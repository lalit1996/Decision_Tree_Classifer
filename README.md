ğŸš— Toyota Car Price Prediction using Machine Learning
ğŸ“Œ Project Overview

This project focuses on predicting Toyota car prices based on features such as model type, manufacturing year, and other attributes.
Multiple machine learning models were evaluated, with a strong emphasis on model validation and pruning techniques to improve generalization performance.

ğŸ¯ Objective

Predict car prices accurately

Compare Linear Regression and Decision Tree models

Reduce overfitting using Cost-Complexity Pruning

Select the best model using cross-validation

ğŸ“Š Dataset Description

The dataset contains information about Toyota cars, including:

Model

Year

Other numerical and categorical features

Target variable: Car Price

ğŸ§  Models Used
1ï¸âƒ£ Linear Regression

Used as a baseline model

Achieved ~78% accuracy

Limited in capturing non-linear relationships

2ï¸âƒ£ Decision Tree Regressor

Implemented with cost-complexity pruning

ccp_alpha values obtained using:

cost_complexity_pruning_path


Each ccp_alpha evaluated using 5-fold Stratified Cross-Validation

Final ccp_alpha selected based on average cross-validation score

âœ… Achieved ~93% accuracy

ğŸ”¬ Model Validation Strategy

Stratified K-Fold Cross Validation (5 folds)

Each pruning level (ccp_alpha) validated across all folds

Mean score used to ensure robust and unbiased performance

ğŸ“ˆ Key Results
Model	Accuracy
Linear Regression	78%
Decision Tree (Optimized)	93%

âœ” Significant performance improvement after pruning and validation
âœ” Reduced overfitting
âœ” Better generalization on unseen data

ğŸ› ï¸ Technologies & Libraries

Python

NumPy

Pandas

Scikit-learn

Matplotlib / Seaborn


ğŸš€ Key Learnings

Proper hyperparameter tuning is critical

Cost-complexity pruning helps control tree overfitting

Cross-validation gives more reliable results than a single train-test split

Model simplicity often improves real-world performance

ğŸ“Œ Conclusion

This project demonstrates how systematic pruning and validation can significantly enhance model performance.
Decision Trees, when properly tuned, can outperform simpler models like Linear Regression for complex, non-linear datasets.
